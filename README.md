# TPF - PredicciÃ³n de Consumo EnergÃ©tico Industrial

Este repositorio contiene el Trabajo PrÃ¡ctico Final para la materia "Laboratorio de Datos II", enfocado en crear un pipeline de MLOps completo para predecir el consumo energÃ©tico de una planta cervecera.

## ðŸŽ¯ Objetivo del Proyecto

El objetivo es desarrollar un pipeline de machine learning reproducible para predecir el consumo energÃ©tico diario (kW) del sistema de refrigeraciÃ³n (`Frio (kW)`) del dÃ­a siguiente. El proyecto se enfoca en buenas prÃ¡cticas de MLOps, control de versiones (Git), versionado de datos (LFS, checksums) y seguimiento de experimentos.

## ðŸ“‚ Estructura del Repositorio

El proyecto sigue una estructura estÃ¡ndar para proyectos de Machine Learning:

tp_final/
â”œâ”€â”€ .git/
â”œâ”€â”€ .gitattributes         # ConfiguraciÃ³n de Git LFS
â”œâ”€â”€ .gitignore             # Archivos ignorados por Git
â”œâ”€â”€ data/                  # Datos brutos, procesados e intermedios
â”‚   â”œâ”€â”€ Totalizadores*.xlsx  # Datos brutos (manejados por Git LFS)
â”‚   â”œâ”€â”€ dataset_unificado.csv
â”‚   â”œâ”€â”€ dataset_preprocesamiento.csv
â”‚   â””â”€â”€ checksums.json     # Checksums para versionado de datos
â”œâ”€â”€ models/                # Modelos entrenados y serializados
â”‚   â”œâ”€â”€ modelo_v1.0.0.pkl  # (Manejado por Git LFS)
â”‚   â””â”€â”€ model_registry.json
â”œâ”€â”€ notebooks/             # Notebooks de exploraciÃ³n, prototipado y borradores
â”‚   â”œâ”€â”€ eda.ipynb
â”‚   â”œâ”€â”€ preprocesamiento.ipynb
â”‚   â””â”€â”€ modelado.ipynb
â”œâ”€â”€ results/               # Resultados finales
â”‚   â”œâ”€â”€ predicciones.csv
â”‚   â””â”€â”€ experiment_logs.csv
â”œâ”€â”€ src/                   # Scripts de cÃ³digo fuente (Python)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ preprocessing_pipeline.py
â”‚   â”œâ”€â”€ train_model.py
â”‚   â”œâ”€â”€ predict.py
â”‚   â””â”€â”€ tools.py           # Funciones auxiliares
â””â”€â”€ requirements.txt       # Lista de dependencias del proyecto

---

## ðŸš€ GuÃ­a de InstalaciÃ³n y EjecuciÃ³n

Sigue estos pasos para clonar y ejecutar el proyecto en tu mÃ¡quina local.

### Paso 1: Clonar el Repositorio

**Â¡IMPORTANTE!** Este proyecto usa **Git LFS** (Large File Storage) para manejar los archivos pesados (como los `.xlsx` y `.pkl`).

1.  **Instala Git LFS** en tu computadora (si no lo tienes). Puedes descargarlo desde [git-lfs.github.com](https://git-lfs.github.com).
2.  Clona el repositorio. El comando `git clone` descargarÃ¡ automÃ¡ticamente los archivos de LFS.

    ```bash
    git clone [https://github.com/Angiii12/TPF_Consumo_Energetico.git](https://github.com/Angiii12/TPF_Consumo_Energetico.git)
    ```
3.  Entra a la carpeta del proyecto:
    ```bash
    cd TPF_Consumo_Energetico
    ```

### Paso 2: Configurar el Entorno Virtual (Conda)

Para asegurar la reproducibilidad, el proyecto usa un entorno de Conda especÃ­fico (`cervecera_env`) y un archivo `requirements.txt`[cite: 26, 40].

1.  **Crea el entorno de Conda** (asegÃºrate de tener Anaconda o Miniconda instalado)[cite: 29]:
    ```bash
    conda create -n cervecera_env python=3.12
    ```
2.  **Activa el entorno:** [cite: 30]
    ```bash
    conda activate cervecera_env
    ```
3.  **Instala todas las dependencias** listadas en `requirements.txt`[cite: 224]:
    ```bash
    pip install -r requirements.txt
    ```

Â¡Listo! Ya tienes el entorno configurado con las mismas librerÃ­as y versiones usadas en el proyecto.

### Paso 3: Ejecutar los Scripts Principales

El pipeline se ejecuta secuencialmente. Debes ejecutar los scripts desde la carpeta raÃ­z del proyecto (`TPF_Consumo_Energetico/`).

1.  **(Opcional) Ejecutar Preprocesamiento:**
    (Este script se usa para generar los datos limpios que usarÃ¡ el entrenamiento) [cite: 120].
    ```bash
    python src/preprocessing_pipeline.py
    ```

2.  **(Opcional) Entrenar el Modelo:**
    (Este script entrena el modelo usando los datos procesados y lo guarda en la carpeta `models/`) [cite: 146].
    ```bash
    python src/train_model.py
    ```

3.  **Ejecutar Predicciones (Script Principal):**
    Este es el script final[cite: 153]. Carga el Ãºltimo modelo entrenado desde `models/` y genera predicciones sobre un archivo de datos nuevos[cite: 212, 213].

    Debes pasarle como argumento la ruta al archivo Excel con los datos nuevos (usando uno de los de prueba como ejemplo):

    ```bash
    python src/predict.py "data/Totalizadores Planta de Cerveza 2021 2022.xlsx"
    ```

    Tras ejecutarse, verÃ¡s un mensaje de Ã©xito y encontrarÃ¡s el archivo `predicciones.csv` en la carpeta `results/`[cite: 209, 210].